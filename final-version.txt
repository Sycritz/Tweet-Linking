This is a final version specification meant to be followed by an agent, The current project has some flaws and improvement I would like to specify so we reach the final version:
- The n-gram generation module when used to generate n-grams should not stop at length 6 rather it should be like what mentioned to the paper and generate n-grams ranging from 1 to length of tweet itself.

- The features implemented in the feature extraction module are not satisfactory rather you should implement the following features further explanation of each feature is provided at provided-rasources/evi--.pdf the reference paper and the features definition are specified under:
          1. Commonness (CMNS):

          - Highest importance across most datasets; measures how often the mention refers to the entity in the context.

          1. LE Overlap (LE Overplap):

          - Significant importance, especially in datasets like NEEL2016DEV, indicating the relevance of textual overlap between the tweet and entity references.

          1. Page Views (vE):

          - Frequently the second most important feature, reflecting entity popularity/popularity.

          1. PageRank (rE):

          - Structural importance within the Wikipedia graph, capturing the centrality of entities.

          1. TF-IDF (TFIDF):

          - Measures the relevance of the mention in the context of entity content; important but ranked below prominence features.

          1. Absorption:

          - Indicates the proportion of anchors contained in the n-gram relative to the references, relevant for relevance.

          1. PURITY (PURITY):

          - Measures the ratio of exact n-gram occurrences in references, contributing to relevance.

          1. DIST (Distinct references):

          - Captures the diversity of references, important for assessing entity prominence and ambiguity.

          1. T OR (Redirect/Anchor Indicator):

          - Flags whether the mention corresponds to a redirect or anchor, influencing the likelihood of correct linking.

          1. Overlap with Categories (CE Overlap):

- The svm and xgboost module are not developped and not finished you should implement them there is no need to bother with grid searching for the best parameters my teammates already did this and found out that svm with kernel polynomial of degree 2 and c =1 is the best performant svm model, while for xgboost we did not run grid search so yeah maybe checking for it is better, the models should be implemented in a clean modular way under the appropriate scripts furthermore should be served in an easy to use i.e take a tweet directly and predict (do the entity linking) the models should be trained only on medji dataset, and should be saved as pkl objects to be used later.

- You should implement an evaluation script that loads the models and evalutes their performance on the other datasets tsv (given and explained in the provided-rasources) should calculate the f-1,percision etc and plot the appropriate graphs etc, there should also be a section for using the tagme and aida apis and evaluating comparing the apis and models performance on the appropriate metrics etc.. The final evaluation script should be clean and should be extensible easily as I plan to play on later with some embedding models so I would like to test them also, i.e when you are done with this final version the evaluation.py script is the one I would use the most so pay attention to coding it, also under the evaluation script there should be a section testing which feature is most important for our work and which has the most impact on the model perfomance use out of the bag techniques for evaluation.

What I want from you is to complete the coding aspect of this boring parts that I already know what to do/ there is noting to learn from and take it to a part where I can serve the project and submit it as it is, however I still want to play with project primarly with embedding models for this usage so the code written should still be easily extensible etc I think I did not forget anything for the project however review the provided-rasources/mathlabproject.pdf for further specification and seeing if there is anything I am missing, the coding style should be like the one I already provided so functional inspired type annotated clean and modular, follow the best practices.
