Tweet Entity Linking System - Project Status & Description
Project Overview
This project implements a robust Entity Linking (EL) system specifically designed for short, noisy text (Tweets). The system identifies entity mentions in tweets and links them to their corresponding entries in a Knowledge Base (Wikipedia/DBpedia).

System Architecture
1. Pipeline Components
Preprocessing: Cleaning tweets, handling hashtags (splitting camelCase), and n-gram generation (up to full tweet length).
Candidate Generation: Retrieving candidate entities for each n-gram using a dictionary-based approach.
Feature Extraction: Computing a rich set of features for each mention-candidate pair:
Prior Probability: Commonness (CMNS).
Contextual: TF-IDF, Reference Probability, Reference Distance.
Coherence: Link Potency, Embeddings similarity.
Graph: PageRank, HITS scores.
Classification: Ranking candidates using machine learning models to select the best link (or NIL).
2. Models Implemented
SVM: Support Vector Machine with Polynomial kernel (degree=2, C=1) for robust non-linear classification.
XGBoost: Gradient Boosting decision trees optimized via grid search for high-performance ranking.
DNN (Deep Neural Network): A custom architecture featuring:
Residual Blocks for deep feature learning.
Batch Normalization and Dropout for regularization.
Learning Rate Scheduling (ReduceLROnPlateau).
Recent Improvements & Changes
Following the review of the initial MVP, the following major enhancements have been implemented to bring the project to a finalized state:

✅ API Baselines & Comparison
DBpedia Spotlight Integration: Added as a replacement for the defunct AIDA MPI service.
Improvement: Implemented robust text-based matching (normalizing titles/mentions) to handle ID discrepancies between datasets and API responses.
Performance: Achieved F1 ~0.48 on dev set.
TagMe Integration:
Fix: Removed hardcoded 100-tweet limit to allow full dataset evaluation.
Feature: Added configurable --max-api-tweets to manage rate limits.
Performance: Verified strong baseline with F1 ~0.81.
Visualization: Added specific Model vs API comparison plots to benchmark local models against these external industry standards.
✅ Evaluation Framework
Dataset Coverage: Expanded evaluation configuration to include all provided datasets by default: NEEL2016-Dev, NEEL2016-Train, Mena, and Meij.
Metrics: Standardized reporting on Precision, Recall, F1, and Accuracy.
✅ Codebase Improvements
Robustness: Added error handling for API timeouts and connection issues.
CLI Enhancements: Added flags (--skip-spotlight, --max-api-tweets) for flexible testing.
Visualization: Enhanced plotting to support comparing multiple models across multiple datasets in a single view.
Current Status
The system is fully functional and capable of running end-to-end training and evaluation. It successfully benchmarks custom ML models against state-of-the-art APIs, providing a comprehensive view of performance across different data distributions (News/Events in NEEL vs. General inconsistencies in Tweets).
